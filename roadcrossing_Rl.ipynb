{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49dc2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Learning + Pygame Simple RL Road Crossing\n",
    "\n",
    "import pygame\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10914c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game settings\n",
    "WIDTH, HEIGHT = 600, 100\n",
    "CELL_SIZE = 100\n",
    "N_CELLS = WIDTH // CELL_SIZE\n",
    "\n",
    "# Q-Learning settings\n",
    "alpha = 0.1\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "min_epsilon = 0.01\n",
    "episodes = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583051f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards\n",
    "REWARD_GOAL = 10\n",
    "REWARD_STEP = -0.1\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "win = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"RL Agent - Road Crossing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42393bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-table: (state, action) -> Q-value\n",
    "q_table = np.zeros((N_CELLS, 2))  # 2 actions: left(0), right(1)\n",
    "\n",
    "# Actions\n",
    "ACTION_LEFT = 0\n",
    "ACTION_RIGHT = 1\n",
    "ACTIONS = [ACTION_LEFT, ACTION_RIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ccd8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw environment\n",
    "def draw(state):\n",
    "    win.fill((255, 255, 255))\n",
    "    \n",
    "    # Draw cells\n",
    "    for i in range(N_CELLS):\n",
    "        rect = pygame.Rect(i * CELL_SIZE, 0, CELL_SIZE, CELL_SIZE)\n",
    "        pygame.draw.rect(win, (200, 200, 200), rect, 2)\n",
    "    \n",
    "    # Draw goal\n",
    "    goal_rect = pygame.Rect((N_CELLS - 1) * CELL_SIZE, 0, CELL_SIZE, CELL_SIZE)\n",
    "    pygame.draw.rect(win, (0, 255, 0), goal_rect)\n",
    "    \n",
    "    # Draw agent\n",
    "    agent_rect = pygame.Rect(state * CELL_SIZE, 0, CELL_SIZE, CELL_SIZE)\n",
    "    pygame.draw.rect(win, (0, 0, 255), agent_rect)\n",
    "    \n",
    "    pygame.display.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "306421f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50/500, epsilon=0.778\n",
      "Episode 100/500, epsilon=0.606\n",
      "Episode 150/500, epsilon=0.471\n",
      "Episode 200/500, epsilon=0.367\n",
      "Episode 250/500, epsilon=0.286\n",
      "Episode 300/500, epsilon=0.222\n",
      "Episode 350/500, epsilon=0.173\n",
      "Episode 400/500, epsilon=0.135\n",
      "Episode 450/500, epsilon=0.105\n",
      "Episode 500/500, epsilon=0.082\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "# Main training loop\n",
    "for ep in range(episodes):\n",
    "    state = 0  # Start at left-most cell\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        # Handle window events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                exit()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(ACTIONS)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "        \n",
    "        # Take action\n",
    "        next_state = state\n",
    "        if action == ACTION_LEFT and state > 0:\n",
    "            next_state -= 1\n",
    "        elif action == ACTION_RIGHT and state < N_CELLS - 1:\n",
    "            next_state += 1\n",
    "        \n",
    "        # Get reward\n",
    "        if next_state == N_CELLS - 1:\n",
    "            reward = REWARD_GOAL\n",
    "            done = True\n",
    "        else:\n",
    "            reward = REWARD_STEP\n",
    "        \n",
    "        # Q-Learning update\n",
    "        old_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        \n",
    "        new_q = old_q + alpha * (reward + gamma * next_max_q - old_q)\n",
    "        q_table[state, action] = new_q\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        # Draw current state\n",
    "        draw(state)\n",
    "        pygame.time.delay(50)\n",
    "    \n",
    "    # Decay epsilon\n",
    "    if epsilon > min_epsilon:\n",
    "        epsilon *= epsilon_decay\n",
    "    \n",
    "    # Print progress\n",
    "    if (ep + 1) % 50 == 0:\n",
    "        print(f\"Episode {ep + 1}/{episodes}, epsilon={epsilon:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd7729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Done training\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Wait before quitting\n",
    "pygame.time.wait(2000)\n",
    "pygame.quit()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
